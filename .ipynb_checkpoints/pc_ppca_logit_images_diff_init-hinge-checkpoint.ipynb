{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import autograd.numpy as np\n",
    "from autograd import grad, hessian\n",
    "from autograd import elementwise_grad\n",
    "from scipy.optimize import fmin_l_bfgs_b, fmin_bfgs, fmin_cg, fmin_ncg\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.linalg import cho_factor, cho_solve, cholesky\n",
    "from autograd.scipy.linalg import solve_triangular\n",
    "from sklearn.decomposition import FactorAnalysis, PCA\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from autograd.misc.optimizers import adam\n",
    "import copy\n",
    "import glob\n",
    "import imageio\n",
    "import skimage\n",
    "from skimage import data, io, filters\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pickle\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda2/lib/python2.7/site-packages/skimage/transform/_warps.py:24: UserWarning: The default multichannel argument (None) is deprecated.  Please specify either True or False explicitly.  multichannel will default to False starting with release 0.16.\n",
      "  warn('The default multichannel argument (None) is deprecated.  Please '\n",
      "/anaconda2/lib/python2.7/site-packages/skimage/transform/_warps.py:105: UserWarning: The default mode, 'constant', will be changed to 'reflect' in skimage 0.15.\n",
      "  warn(\"The default mode, 'constant', will be changed to 'reflect' in \"\n",
      "/anaconda2/lib/python2.7/site-packages/skimage/transform/_warps.py:110: UserWarning: Anti-aliasing will be enabled by default in skimage 0.15 to avoid aliasing artifacts when down-sampling images.\n",
      "  warn(\"Anti-aliasing will be enabled by default in skimage 0.15 to \"\n"
     ]
    }
   ],
   "source": [
    "def get_labels(filenames):\n",
    "    labels = np.zeros(len(filenames))\n",
    "    for i in range(len(filenames)):\n",
    "        if any(s in filenames[i] for s in ('sad', 'wink', 'surprised', 'sleepy', 'happy')):\n",
    "            labels[i] = 1\n",
    "    return labels\n",
    "\n",
    "\n",
    "img_arr_train = np.array([skimage.img_as_float(skimage.transform.rescale(imageio.imread(file),1.0 / 4.0)) for file in glob.glob('yale_train/*png')])\n",
    "img_arr_test = np.array([skimage.img_as_float(skimage.transform.rescale(imageio.imread(file),1.0 / 4.0)) for file in glob.glob('yale_test/*png')])\n",
    "X_train = np.reshape(img_arr_train, (img_arr_train.shape[0], img_arr_train.shape[1]*img_arr_train.shape[2]))\n",
    "X_test = np.reshape(img_arr_test, (img_arr_test.shape[0], img_arr_test.shape[1]*img_arr_test.shape[2]))\n",
    "y_train = get_labels(glob.glob('yale_train/*png'))\n",
    "y_test = get_labels(glob.glob('yale_test/*png'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "\n",
    "def hinge(x):\n",
    "    return -np.maximum(0.0, 1.0 - x)\n",
    "\n",
    "def objective_logit (params, x, y, latent_dim, lambda_e, opt): #check the order of arguments!\n",
    "    N = x.shape[0]\n",
    "    D = x.shape[1]\n",
    "    f, bias_x, cov_noise, w = decode_parameters(params, D, latent_dim, opt)\n",
    "        \n",
    "    cov_x = np.einsum(\"dl,ml->dm\",f,f) + cov_noise\n",
    "    #print cov_x.shape\n",
    "    sign, log_det_cov_x = np.linalg.slogdet(cov_x)\n",
    "    #print log_det_cov_x\n",
    "    temp1 = np.linalg.solve(cov_x, (x - bias_x).T)\n",
    "    unnorm_log_pdf_x = np.einsum(\"nd,dn->n\", x - bias_x, temp1)\n",
    "    ll = N*D*np.log(2*np.pi)/2 + log_det_cov_x*0.5*N + np.sum(unnorm_log_pdf_x)*0.5 \n",
    "\n",
    "    mean_z = np.einsum(\"dl,dn->nl\", f, temp1)\n",
    "    temp2 = np.einsum(\"l,nl->n\", w[1:], mean_z) + w[0]\n",
    "    log_bern_pdf_y = np.log(sigmoid(np.multiply((2*y-1),temp2)))\n",
    "    log_prior = 0 \n",
    "    lambda_r = 1\n",
    "    reg1 = lambda_r*np.sum(f**2)\n",
    "    reg2 = lambda_r*np.sum(w**2)\n",
    "    reg = reg1+reg2\n",
    "    ll = ll - lambda_e*np.sum(log_bern_pdf_y) - log_prior + reg\n",
    "    return ll\n",
    "\n",
    "def objective_logit_fast(params, x, y, latent_dim, lambda_e, opt, reg_weight): #check the order of arguments!\n",
    "    N = x.shape[0]\n",
    "    D = x.shape[1]\n",
    "    f, bias_x, cov_noise, w = decode_parameters_fast(params, D, latent_dim, opt)\n",
    "    L = f.shape[1]\n",
    "        \n",
    "    icn = (1.0 / cov_noise).reshape((-1, 1))\n",
    "    xn = (x - bias_x).T\n",
    "    Ax = icn * xn\n",
    "    Au = icn * f\n",
    "    C = np.eye(L) + np.dot(f.T, Au)\n",
    "    temp1 = np.dot(f.T, Ax)\n",
    "    temp1 = np.linalg.solve(C, temp1)\n",
    "    temp1 = np.dot(Au, temp1)\n",
    "    temp1 = Ax - temp1\n",
    "    sign, log_det_cov_x = np.linalg.slogdet(C)\n",
    "    log_det_cov_x += np.sum(np.log(cov_noise))\n",
    "    \n",
    "    unnorm_log_pdf_x = np.einsum(\"dn,dn->n\", xn, temp1)\n",
    "    \n",
    "    mean_z = np.dot(f.T, temp1).T\n",
    "    temp2 = np.einsum(\"l,nl->n\", w[1:], mean_z) + w[0]\n",
    "    log_bern_pdf_y = np.log(sigmoid(np.multiply((2*y-1),temp2)))\n",
    "    log_prior = 0 \n",
    "    reg = reg_weight*np.sum((f/np.sqrt(D))**2) + reg_weight*np.sum(w**2)\n",
    "    ll = N*D*np.log(2*np.pi)/2 + log_det_cov_x*0.5*N + np.sum(unnorm_log_pdf_x)*0.5 \n",
    "    obj = ll - lambda_e*np.sum(log_bern_pdf_y) - log_prior + reg\n",
    "    return obj\n",
    "\n",
    "def objective_hinge_fast(params, x, y, latent_dim, lambda_e, opt, reg_weight): #check the order of arguments!\n",
    "    N = x.shape[0]\n",
    "    D = x.shape[1]\n",
    "    f, bias_x, cov_noise, w = decode_parameters_fast(params, D, latent_dim, opt)\n",
    "    L = f.shape[1]\n",
    "        \n",
    "    icn = (1.0 / cov_noise).reshape((-1, 1))\n",
    "    xn = (x - bias_x).T\n",
    "    Ax = icn * xn\n",
    "    Au = icn * f\n",
    "    C = np.eye(L) + np.dot(f.T, Au)\n",
    "    temp1 = np.dot(f.T, Ax)\n",
    "    temp1 = np.linalg.solve(C, temp1)\n",
    "    temp1 = np.dot(Au, temp1)\n",
    "    temp1 = Ax - temp1\n",
    "    sign, log_det_cov_x = np.linalg.slogdet(C)\n",
    "    log_det_cov_x += np.sum(np.log(cov_noise))\n",
    "    \n",
    "    unnorm_log_pdf_x = np.einsum(\"dn,dn->n\", xn, temp1)\n",
    "    \n",
    "    mean_z = np.dot(f.T, temp1).T\n",
    "    temp2 = np.einsum(\"l,nl->n\", w[1:], mean_z) + w[0]\n",
    "    hinge_bern_pdf_y = hinge(np.multiply((2*y-1),temp2))\n",
    "    log_prior = 0 \n",
    "    reg = reg_weight*np.sum((f/np.sqrt(D))**2) + reg_weight*np.sum(w**2)\n",
    "    ll = N*D*np.log(2*np.pi)/2 + log_det_cov_x*0.5*N + np.sum(unnorm_log_pdf_x)*0.5 \n",
    "    obj = ll - lambda_e*np.sum(hinge_bern_pdf_y) - log_prior + reg\n",
    "    return obj\n",
    "\n",
    "def decode_parameters_fast(params, D, latent_dim, opt):\n",
    "    size_f = D*latent_dim\n",
    "    f =  params[:size_f]\n",
    "    #f = f*np.array([0,1]) + np.array([1,0])\n",
    "    f =  f.reshape(D, latent_dim)\n",
    "    bias_x = params[size_f:size_f+D]\n",
    "    if (opt==\"ppca\"):\n",
    "        var = params[size_f+D]\n",
    "        cov_noise= np.ones(D)*np.log(1+np.exp(var))\n",
    "        #cov_noise= np.diag(np.ones(D)*np.exp(var))\n",
    "        w = params[size_f+D+1:]\n",
    "    else:\n",
    "        var = params[size_f+D:size_f+D*2]\n",
    "        cov_noise = np.log(1+np.exp(var))\n",
    "        w = params[size_f+D*2:]\n",
    "    return f, bias_x, cov_noise, w\n",
    "\n",
    "def decode_parameters(params, D, latent_dim, opt):\n",
    "    size_f = D*latent_dim\n",
    "    f =  params[:size_f]\n",
    "    #f = f*np.array([0,1]) + np.array([1,0])\n",
    "    f =  f.reshape(D, latent_dim)\n",
    "    bias_x = params[size_f:size_f+D]\n",
    "    if (opt==\"ppca\"):\n",
    "        var = params[size_f+D]\n",
    "        cov_noise= np.diag(np.ones(D)*np.log(1+np.exp(var)))\n",
    "        #cov_noise= np.diag(np.ones(D)*np.exp(var))\n",
    "        w = params[size_f+D+1:]\n",
    "    else:\n",
    "        var = params[size_f+D:size_f+D*2]\n",
    "        cov_noise= np.diag(np.log(1+np.exp(var)))\n",
    "        w = params[size_f+D*2:]\n",
    "    return f, bias_x, cov_noise, w\n",
    "\n",
    "def transform(f, bias, cov_noise, x):\n",
    "    cov_x = np.einsum(\"dl,ml->dm\",f,f) + cov_noise\n",
    "    temp = np.linalg.solve(cov_x, (x - bias).T)\n",
    "    mean_z = np.einsum(\"dl,dn->nl\", f, temp)\n",
    "    return mean_z\n",
    "\n",
    "    \n",
    "def compute_ll(f,bias,cov_noise, x):\n",
    "    N = x.shape[0]\n",
    "    D = x.shape[1]\n",
    "    cov_x = np.einsum(\"dl,ml->dm\",f,f) + cov_noise\n",
    "    sign, log_det_cov_x = np.linalg.slogdet(cov_x)\n",
    "    temp1 = np.linalg.solve(cov_x, (x - bias).T)\n",
    "    ll = N*D*np.log(2*np.pi)/2\n",
    "    ll += log_det_cov_x*N/2\n",
    "    ll += np.sum(np.einsum(\"nd,dn->n\", x - bias, temp1))/2\n",
    "    return -ll\n",
    "\n",
    "def compute_ll_fast(params, x, latent_dim, opt):\n",
    "    N = x.shape[0]\n",
    "    D = x.shape[1]\n",
    "    f, bias_x, cov_noise, w = decode_parameters_fast(params, D, latent_dim, opt)\n",
    "    L = f.shape[1]\n",
    "        \n",
    "    icn = (1.0 / cov_noise).reshape((-1, 1))\n",
    "    xn = (x - bias_x).T\n",
    "    Ax = icn * xn\n",
    "    Au = icn * f\n",
    "    C = np.eye(L) + np.dot(f.T, Au)\n",
    "    temp1 = np.dot(f.T, Ax)\n",
    "    temp1 = np.linalg.solve(C, temp1)\n",
    "    temp1 = np.dot(Au, temp1)\n",
    "    temp1 = Ax - temp1\n",
    "    sign, log_det_cov_x = np.linalg.slogdet(C)\n",
    "    log_det_cov_x += np.sum(np.log(cov_noise))\n",
    "    \n",
    "    unnorm_log_pdf_x = np.einsum(\"dn,dn->n\", xn, temp1)\n",
    "    \n",
    "    ll = N*D*np.log(2*np.pi)/2 + log_det_cov_x*0.5*N + np.sum(unnorm_log_pdf_x)*0.5 \n",
    "    return -ll\n",
    "\n",
    "\n",
    "def compute_pll_logit(f, bias_x, cov_noise, w, x, y):\n",
    "    cov_x = np.einsum(\"dl,ml->dm\",f,f) + cov_noise\n",
    "    temp1 = np.linalg.solve(cov_x, (x - bias_x).T)\n",
    "    \n",
    "    mean_z = np.einsum(\"dl,dn->nl\", f, temp1)\n",
    "    temp2 = np.einsum(\"l,nl->n\", w[1:], mean_z) + w[0]\n",
    "    log_bern_pdf_y = np.log(sigmoid(np.multiply((2*y-1),temp2)))\n",
    "    return np.sum(log_bern_pdf_y)\n",
    "\n",
    "def compute_pll_logit_fast(params, x, y, latent_dim, opt):\n",
    "    N = x.shape[0]\n",
    "    D = x.shape[1]\n",
    "    f, bias_x, cov_noise, w = decode_parameters_fast(params, D, latent_dim, opt)\n",
    "    L = f.shape[1]\n",
    "        \n",
    "    icn = (1.0 / cov_noise).reshape((-1, 1))\n",
    "    xn = (x - bias_x).T\n",
    "    Ax = icn * xn\n",
    "    Au = icn * f\n",
    "    C = np.eye(L) + np.dot(f.T, Au)\n",
    "    temp1 = np.dot(f.T, Ax)\n",
    "    temp1 = np.linalg.solve(C, temp1)\n",
    "    temp1 = np.dot(Au, temp1)\n",
    "    temp1 = Ax - temp1\n",
    "    \n",
    "    mean_z = np.dot(f.T, temp1).T\n",
    "    temp2 = np.einsum(\"l,nl->n\", w[1:], mean_z) + w[0]\n",
    "    log_bern_pdf_y = np.log(sigmoid(np.multiply((2*y-1),temp2)))\n",
    "    return np.sum(log_bern_pdf_y)\n",
    "\n",
    "def compute_hinge_loss_fast(params, x, y, latent_dim, opt):\n",
    "    N = x.shape[0]\n",
    "    D = x.shape[1]\n",
    "    f, bias_x, cov_noise, w = decode_parameters_fast(params, D, latent_dim, opt)\n",
    "    L = f.shape[1]\n",
    "        \n",
    "    icn = (1.0 / cov_noise).reshape((-1, 1))\n",
    "    xn = (x - bias_x).T\n",
    "    Ax = icn * xn\n",
    "    Au = icn * f\n",
    "    C = np.eye(L) + np.dot(f.T, Au)\n",
    "    temp1 = np.dot(f.T, Ax)\n",
    "    temp1 = np.linalg.solve(C, temp1)\n",
    "    temp1 = np.dot(Au, temp1)\n",
    "    temp1 = Ax - temp1\n",
    "    \n",
    "    mean_z = np.dot(f.T, temp1).T\n",
    "    temp2 = np.einsum(\"l,nl->n\", w[1:], mean_z) + w[0]\n",
    "    \n",
    "    hinge_bern_pdf_y = hinge(np.multiply((2*y-1),temp2))\n",
    "    \n",
    "    return np.sum(hinge_bern_pdf_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "latent_dim = 2\n",
    "x_dim = X_train.shape[1]      \n",
    "params_size = x_dim*latent_dim + x_dim + 1 + latent_dim + 1\n",
    "opt = \"ppca\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda2/lib/python2.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "clf_orig = LogisticRegression().fit(X_train, y_train)\n",
    "test_acc_orig = clf_orig.score(X_test, y_test)\n",
    "print test_acc_orig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.525\n"
     ]
    }
   ],
   "source": [
    "transformer = PCA(latent_dim)\n",
    "x_train_transformed_pca = transformer.fit_transform(X_train)\n",
    "x_test_transformed_pca = transformer.transform(X_test)\n",
    "clf_pca = LogisticRegression().fit(x_train_transformed_pca, y_train)\n",
    "test_acc_pca = clf_pca.score(x_test_transformed_pca, y_test)\n",
    "print test_acc_pca"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg_weights = np.array([0, 1e2, 1e3, 1e4, 1e5])\n",
    "#reg_weights = np.array([1e3])\n",
    "\n",
    "pred_weights = np.array([0, 1e2, 1e3,1e4, 1e5, 1e6, 1e7, 1e8, 1e9, 1e10])\n",
    "#pred_weights = np.array([1e4])\n",
    "\n",
    "num_inits = 10\n",
    "\n",
    "params_opt_l_bfgs_b = np.zeros((num_inits, reg_weights.shape[0], pred_weights.shape[0], params_size))\n",
    "final_obj_val_l_bfgs_b = np.zeros((num_inits, reg_weights.shape[0], pred_weights.shape[0]))\n",
    "init_params = np.zeros((num_inits, params_size))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "init, 0\n",
      "reg_weight:  0.0\n",
      "pred_weight:  0.0\n",
      "pred_weight:  100.0\n",
      "pred_weight:  1000.0\n",
      "pred_weight:  10000.0\n",
      "pred_weight:  100000.0\n",
      "pred_weight:  1000000.0\n",
      "pred_weight:  10000000.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda2/lib/python2.7/site-packages/autograd/numpy/numpy_vjps.py:73: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  defvjp(anp.exp,    lambda ans, x : lambda g: ans * g)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pred_weight:  100000000.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda2/lib/python2.7/site-packages/autograd/tracer.py:48: RuntimeWarning: divide by zero encountered in log\n",
      "  return f_raw(*args, **kwargs)\n",
      "/anaconda2/lib/python2.7/site-packages/autograd/numpy/numpy_vjps.py:76: RuntimeWarning: divide by zero encountered in divide\n",
      "  defvjp(anp.log,    lambda ans, x : lambda g: g / x)\n",
      "/anaconda2/lib/python2.7/site-packages/autograd/numpy/numpy_vjps.py:39: RuntimeWarning: invalid value encountered in divide\n",
      "  lambda ans, x, y : unbroadcast_f(y, lambda g: - g * x / y**2))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pred_weight:  1000000000.0\n",
      "pred_weight:  10000000000.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda2/lib/python2.7/site-packages/ipykernel_launcher.py:37: RuntimeWarning: divide by zero encountered in divide\n",
      "/anaconda2/lib/python2.7/site-packages/numpy/linalg/linalg.py:1965: RuntimeWarning: invalid value encountered in slogdet\n",
      "  sign, logdet = _umath_linalg.slogdet(a, signature=signature)\n",
      "/anaconda2/lib/python2.7/site-packages/autograd/tracer.py:48: RuntimeWarning: divide by zero encountered in divide\n",
      "  return f_raw(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reg_weight:  100.0\n",
      "pred_weight:  0.0\n",
      "pred_weight:  100.0\n",
      "pred_weight:  1000.0\n",
      "pred_weight:  10000.0\n",
      "pred_weight:  100000.0\n",
      "pred_weight:  1000000.0\n",
      "pred_weight:  10000000.0\n",
      "pred_weight:  100000000.0\n",
      "pred_weight:  1000000000.0\n",
      "pred_weight:  10000000000.0\n",
      "reg_weight:  1000.0\n",
      "pred_weight:  0.0\n",
      "pred_weight:  100.0\n",
      "pred_weight:  1000.0\n",
      "pred_weight:  10000.0\n",
      "pred_weight:  100000.0\n",
      "pred_weight:  1000000.0\n",
      "pred_weight:  10000000.0\n",
      "pred_weight:  100000000.0\n",
      "pred_weight:  1000000000.0\n",
      "pred_weight:  10000000000.0\n",
      "reg_weight:  10000.0\n",
      "pred_weight:  0.0\n",
      "pred_weight:  100.0\n",
      "pred_weight:  1000.0\n",
      "pred_weight:  10000.0\n",
      "pred_weight:  100000.0\n",
      "pred_weight:  1000000.0\n",
      "pred_weight:  10000000.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda2/lib/python2.7/site-packages/autograd/numpy/numpy_vjps.py:76: RuntimeWarning: overflow encountered in divide\n",
      "  defvjp(anp.log,    lambda ans, x : lambda g: g / x)\n",
      "/anaconda2/lib/python2.7/site-packages/autograd/numpy/numpy_vjps.py:39: RuntimeWarning: overflow encountered in square\n",
      "  lambda ans, x, y : unbroadcast_f(y, lambda g: - g * x / y**2))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pred_weight:  100000000.0\n",
      "pred_weight:  1000000000.0\n",
      "pred_weight:  10000000000.0\n",
      "reg_weight:  100000.0\n",
      "pred_weight:  0.0\n",
      "pred_weight:  100.0\n",
      "pred_weight:  1000.0\n",
      "pred_weight:  10000.0\n",
      "pred_weight:  100000.0\n",
      "pred_weight:  1000000.0\n",
      "pred_weight:  10000000.0\n",
      "pred_weight:  100000000.0\n",
      "pred_weight:  1000000000.0\n",
      "pred_weight:  10000000000.0\n",
      "init, 1\n",
      "reg_weight:  0.0\n",
      "pred_weight:  0.0\n",
      "pred_weight:  100.0\n",
      "pred_weight:  1000.0\n",
      "pred_weight:  10000.0\n",
      "pred_weight:  100000.0\n",
      "pred_weight:  1000000.0\n",
      "pred_weight:  10000000.0\n",
      "pred_weight:  100000000.0\n",
      "pred_weight:  1000000000.0\n",
      "pred_weight:  10000000000.0\n",
      "reg_weight:  100.0\n",
      "pred_weight:  0.0\n",
      "pred_weight:  100.0\n",
      "pred_weight:  1000.0\n",
      "pred_weight:  10000.0\n",
      "pred_weight:  100000.0\n",
      "pred_weight:  1000000.0\n",
      "pred_weight:  10000000.0\n",
      "pred_weight:  100000000.0\n",
      "pred_weight:  1000000000.0\n",
      "pred_weight:  10000000000.0\n",
      "reg_weight:  1000.0\n",
      "pred_weight:  0.0\n",
      "pred_weight:  100.0\n",
      "pred_weight:  1000.0\n",
      "pred_weight:  10000.0\n",
      "pred_weight:  100000.0\n",
      "pred_weight:  1000000.0\n",
      "pred_weight:  10000000.0\n",
      "pred_weight:  100000000.0\n",
      "pred_weight:  1000000000.0\n",
      "pred_weight:  10000000000.0\n",
      "reg_weight:  10000.0\n",
      "pred_weight:  0.0\n",
      "pred_weight:  100.0\n",
      "pred_weight:  1000.0\n",
      "pred_weight:  10000.0\n",
      "pred_weight:  100000.0\n",
      "pred_weight:  1000000.0\n",
      "pred_weight:  10000000.0\n",
      "pred_weight:  100000000.0\n",
      "pred_weight:  1000000000.0\n",
      "pred_weight:  10000000000.0\n",
      "reg_weight:  100000.0\n",
      "pred_weight:  0.0\n",
      "pred_weight:  100.0\n",
      "pred_weight:  1000.0\n",
      "pred_weight:  10000.0\n",
      "pred_weight:  100000.0\n",
      "pred_weight:  1000000.0\n",
      "pred_weight:  10000000.0\n",
      "pred_weight:  100000000.0\n",
      "pred_weight:  1000000000.0\n",
      "pred_weight:  10000000000.0\n",
      "init, 2\n",
      "reg_weight:  0.0\n",
      "pred_weight:  0.0\n",
      "pred_weight:  100.0\n",
      "pred_weight:  1000.0\n",
      "pred_weight:  10000.0\n",
      "pred_weight:  100000.0\n",
      "pred_weight:  1000000.0\n",
      "pred_weight:  10000000.0\n",
      "pred_weight:  100000000.0\n",
      "pred_weight:  1000000000.0\n",
      "pred_weight:  10000000000.0\n",
      "reg_weight:  100.0\n",
      "pred_weight:  0.0\n",
      "pred_weight:  100.0\n",
      "pred_weight:  1000.0\n",
      "pred_weight:  10000.0\n",
      "pred_weight:  100000.0\n",
      "pred_weight:  1000000.0\n",
      "pred_weight:  10000000.0\n",
      "pred_weight:  100000000.0\n",
      "pred_weight:  1000000000.0\n",
      "pred_weight:  10000000000.0\n",
      "reg_weight:  1000.0\n",
      "pred_weight:  0.0\n",
      "pred_weight:  100.0\n",
      "pred_weight:  1000.0\n",
      "pred_weight:  10000.0\n",
      "pred_weight:  100000.0\n",
      "pred_weight:  1000000.0\n",
      "pred_weight:  10000000.0\n",
      "pred_weight:  100000000.0\n",
      "pred_weight:  1000000000.0\n",
      "pred_weight:  10000000000.0\n",
      "reg_weight:  10000.0\n",
      "pred_weight:  0.0\n",
      "pred_weight:  100.0\n",
      "pred_weight:  1000.0\n",
      "pred_weight:  10000.0\n",
      "pred_weight:  100000.0\n",
      "pred_weight:  1000000.0\n",
      "pred_weight:  10000000.0\n",
      "pred_weight:  100000000.0\n",
      "pred_weight:  1000000000.0\n",
      "pred_weight:  10000000000.0\n",
      "reg_weight:  100000.0\n",
      "pred_weight:  0.0\n",
      "pred_weight:  100.0\n",
      "pred_weight:  1000.0\n",
      "pred_weight:  10000.0\n",
      "pred_weight:  100000.0\n",
      "pred_weight:  1000000.0\n",
      "pred_weight:  10000000.0\n",
      "pred_weight:  100000000.0\n",
      "pred_weight:  1000000000.0\n",
      "pred_weight:  10000000000.0\n",
      "init, 3\n",
      "reg_weight:  0.0\n",
      "pred_weight:  0.0\n",
      "pred_weight:  100.0\n",
      "pred_weight:  1000.0\n",
      "pred_weight:  10000.0\n",
      "pred_weight:  100000.0\n",
      "pred_weight:  1000000.0\n",
      "pred_weight:  10000000.0\n",
      "pred_weight:  100000000.0\n",
      "pred_weight:  1000000000.0\n",
      "pred_weight:  10000000000.0\n",
      "reg_weight:  100.0\n",
      "pred_weight:  0.0\n",
      "pred_weight:  100.0\n",
      "pred_weight:  1000.0\n",
      "pred_weight:  10000.0\n",
      "pred_weight:  100000.0\n",
      "pred_weight:  1000000.0\n",
      "pred_weight:  10000000.0\n",
      "pred_weight:  100000000.0\n",
      "pred_weight:  1000000000.0\n",
      "pred_weight:  10000000000.0\n",
      "reg_weight:  1000.0\n",
      "pred_weight:  0.0\n",
      "pred_weight:  100.0\n",
      "pred_weight:  1000.0\n",
      "pred_weight:  10000.0\n",
      "pred_weight:  100000.0\n",
      "pred_weight:  1000000.0\n",
      "pred_weight:  10000000.0\n",
      "pred_weight:  100000000.0\n",
      "pred_weight:  1000000000.0\n",
      "pred_weight:  10000000000.0\n",
      "reg_weight:  10000.0\n",
      "pred_weight:  0.0\n",
      "pred_weight:  100.0\n",
      "pred_weight:  1000.0\n",
      "pred_weight:  10000.0\n",
      "pred_weight:  100000.0\n",
      "pred_weight:  1000000.0\n",
      "pred_weight:  10000000.0\n",
      "pred_weight:  100000000.0\n",
      "pred_weight:  1000000000.0\n",
      "pred_weight:  10000000000.0\n",
      "reg_weight:  100000.0\n",
      "pred_weight:  0.0\n",
      "pred_weight:  100.0\n",
      "pred_weight:  1000.0\n",
      "pred_weight:  10000.0\n",
      "pred_weight:  100000.0\n",
      "pred_weight:  1000000.0\n",
      "pred_weight:  10000000.0\n",
      "pred_weight:  100000000.0\n",
      "pred_weight:  1000000000.0\n",
      "pred_weight:  10000000000.0\n",
      "init, 4\n",
      "reg_weight:  0.0\n",
      "pred_weight:  0.0\n",
      "pred_weight:  100.0\n",
      "pred_weight:  1000.0\n",
      "pred_weight:  10000.0\n",
      "pred_weight:  100000.0\n",
      "pred_weight:  1000000.0\n",
      "pred_weight:  10000000.0\n",
      "pred_weight:  100000000.0\n",
      "pred_weight:  1000000000.0\n",
      "pred_weight:  10000000000.0\n",
      "reg_weight:  100.0\n",
      "pred_weight:  0.0\n",
      "pred_weight:  100.0\n",
      "pred_weight:  1000.0\n",
      "pred_weight:  10000.0\n",
      "pred_weight:  100000.0\n",
      "pred_weight:  1000000.0\n",
      "pred_weight:  10000000.0\n",
      "pred_weight:  100000000.0\n",
      "pred_weight:  1000000000.0\n",
      "pred_weight:  10000000000.0\n",
      "reg_weight:  1000.0\n",
      "pred_weight:  0.0\n",
      "pred_weight:  100.0\n",
      "pred_weight:  1000.0\n",
      "pred_weight:  10000.0\n",
      "pred_weight:  100000.0\n",
      "pred_weight:  1000000.0\n",
      "pred_weight:  10000000.0\n",
      "pred_weight:  100000000.0\n",
      "pred_weight:  1000000000.0\n",
      "pred_weight:  10000000000.0\n",
      "reg_weight:  10000.0\n",
      "pred_weight:  0.0\n",
      "pred_weight:  100.0\n",
      "pred_weight:  1000.0\n",
      "pred_weight:  10000.0\n",
      "pred_weight:  100000.0\n",
      "pred_weight:  1000000.0\n",
      "pred_weight:  10000000.0\n",
      "pred_weight:  100000000.0\n",
      "pred_weight:  1000000000.0\n",
      "pred_weight:  10000000000.0\n",
      "reg_weight:  100000.0\n",
      "pred_weight:  0.0\n",
      "pred_weight:  100.0\n",
      "pred_weight:  1000.0\n",
      "pred_weight:  10000.0\n",
      "pred_weight:  100000.0\n",
      "pred_weight:  1000000.0\n",
      "pred_weight:  10000000.0\n",
      "pred_weight:  100000000.0\n",
      "pred_weight:  1000000000.0\n",
      "pred_weight:  10000000000.0\n",
      "init, 5\n",
      "reg_weight:  0.0\n",
      "pred_weight:  0.0\n",
      "pred_weight:  100.0\n",
      "pred_weight:  1000.0\n",
      "pred_weight:  10000.0\n",
      "pred_weight:  100000.0\n",
      "pred_weight:  1000000.0\n",
      "pred_weight:  10000000.0\n",
      "pred_weight:  100000000.0\n",
      "pred_weight:  1000000000.0\n",
      "pred_weight:  10000000000.0\n",
      "reg_weight:  100.0\n",
      "pred_weight:  0.0\n",
      "pred_weight:  100.0\n",
      "pred_weight:  1000.0\n",
      "pred_weight:  10000.0\n",
      "pred_weight:  100000.0\n",
      "pred_weight:  1000000.0\n",
      "pred_weight:  10000000.0\n",
      "pred_weight:  100000000.0\n",
      "pred_weight:  1000000000.0\n",
      "pred_weight:  10000000000.0\n",
      "reg_weight:  1000.0\n",
      "pred_weight:  0.0\n",
      "pred_weight:  100.0\n",
      "pred_weight:  1000.0\n",
      "pred_weight:  10000.0\n",
      "pred_weight:  100000.0\n",
      "pred_weight:  1000000.0\n",
      "pred_weight:  10000000.0\n",
      "pred_weight:  100000000.0\n",
      "pred_weight:  1000000000.0\n",
      "pred_weight:  10000000000.0\n",
      "reg_weight:  10000.0\n",
      "pred_weight:  0.0\n",
      "pred_weight:  100.0\n",
      "pred_weight:  1000.0\n",
      "pred_weight:  10000.0\n",
      "pred_weight:  100000.0\n",
      "pred_weight:  1000000.0\n",
      "pred_weight:  10000000.0\n",
      "pred_weight:  100000000.0\n",
      "pred_weight:  1000000000.0\n",
      "pred_weight:  10000000000.0\n",
      "reg_weight:  100000.0\n",
      "pred_weight:  0.0\n",
      "pred_weight:  100.0\n",
      "pred_weight:  1000.0\n",
      "pred_weight:  10000.0\n",
      "pred_weight:  100000.0\n",
      "pred_weight:  1000000.0\n",
      "pred_weight:  10000000.0\n",
      "pred_weight:  100000000.0\n",
      "pred_weight:  1000000000.0\n",
      "pred_weight:  10000000000.0\n",
      "init, 6\n",
      "reg_weight:  0.0\n",
      "pred_weight:  0.0\n",
      "pred_weight:  100.0\n",
      "pred_weight:  1000.0\n",
      "pred_weight:  10000.0\n",
      "pred_weight:  100000.0\n",
      "pred_weight:  1000000.0\n",
      "pred_weight:  10000000.0\n",
      "pred_weight:  100000000.0\n",
      "pred_weight:  1000000000.0\n",
      "pred_weight:  10000000000.0\n",
      "reg_weight:  100.0\n",
      "pred_weight:  0.0\n",
      "pred_weight:  100.0\n",
      "pred_weight:  1000.0\n",
      "pred_weight:  10000.0\n",
      "pred_weight:  100000.0\n",
      "pred_weight:  1000000.0\n",
      "pred_weight:  10000000.0\n",
      "pred_weight:  100000000.0\n",
      "pred_weight:  1000000000.0\n",
      "pred_weight:  10000000000.0\n",
      "reg_weight:  1000.0\n",
      "pred_weight:  0.0\n",
      "pred_weight:  100.0\n",
      "pred_weight:  1000.0\n",
      "pred_weight:  10000.0\n",
      "pred_weight:  100000.0\n",
      "pred_weight:  1000000.0\n",
      "pred_weight:  10000000.0\n",
      "pred_weight:  100000000.0\n",
      "pred_weight:  1000000000.0\n",
      "pred_weight:  10000000000.0\n",
      "reg_weight:  10000.0\n",
      "pred_weight:  0.0\n",
      "pred_weight:  100.0\n",
      "pred_weight:  1000.0\n",
      "pred_weight:  10000.0\n",
      "pred_weight:  100000.0\n",
      "pred_weight:  1000000.0\n",
      "pred_weight:  10000000.0\n",
      "pred_weight:  100000000.0\n",
      "pred_weight:  1000000000.0\n",
      "pred_weight:  10000000000.0\n",
      "reg_weight:  100000.0\n",
      "pred_weight:  0.0\n",
      "pred_weight:  100.0\n",
      "pred_weight:  1000.0\n",
      "pred_weight:  10000.0\n",
      "pred_weight:  100000.0\n",
      "pred_weight:  1000000.0\n",
      "pred_weight:  10000000.0\n",
      "pred_weight:  100000000.0\n",
      "pred_weight:  1000000000.0\n",
      "pred_weight:  10000000000.0\n",
      "init, 7\n",
      "reg_weight:  0.0\n",
      "pred_weight:  0.0\n",
      "pred_weight:  100.0\n",
      "pred_weight:  1000.0\n",
      "pred_weight:  10000.0\n",
      "pred_weight:  100000.0\n",
      "pred_weight:  1000000.0\n",
      "pred_weight:  10000000.0\n",
      "pred_weight:  100000000.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pred_weight:  1000000000.0\n",
      "pred_weight:  10000000000.0\n",
      "reg_weight:  100.0\n",
      "pred_weight:  0.0\n",
      "pred_weight:  100.0\n",
      "pred_weight:  1000.0\n",
      "pred_weight:  10000.0\n",
      "pred_weight:  100000.0\n",
      "pred_weight:  1000000.0\n",
      "pred_weight:  10000000.0\n",
      "pred_weight:  100000000.0\n",
      "pred_weight:  1000000000.0\n",
      "pred_weight:  10000000000.0\n",
      "reg_weight:  1000.0\n",
      "pred_weight:  0.0\n",
      "pred_weight:  100.0\n",
      "pred_weight:  1000.0\n",
      "pred_weight:  10000.0\n",
      "pred_weight:  100000.0\n",
      "pred_weight:  1000000.0\n",
      "pred_weight:  10000000.0\n",
      "pred_weight:  100000000.0\n",
      "pred_weight:  1000000000.0\n",
      "pred_weight:  10000000000.0\n",
      "reg_weight:  10000.0\n",
      "pred_weight:  0.0\n",
      "pred_weight:  100.0\n",
      "pred_weight:  1000.0\n",
      "pred_weight:  10000.0\n",
      "pred_weight:  100000.0\n",
      "pred_weight:  1000000.0\n",
      "pred_weight:  10000000.0\n",
      "pred_weight:  100000000.0\n",
      "pred_weight:  1000000000.0\n",
      "pred_weight:  10000000000.0\n",
      "reg_weight:  100000.0\n",
      "pred_weight:  0.0\n",
      "pred_weight:  100.0\n",
      "pred_weight:  1000.0\n",
      "pred_weight:  10000.0\n",
      "pred_weight:  100000.0\n",
      "pred_weight:  1000000.0\n",
      "pred_weight:  10000000.0\n",
      "pred_weight:  100000000.0\n",
      "pred_weight:  1000000000.0\n",
      "pred_weight:  10000000000.0\n",
      "init, 8\n",
      "reg_weight:  0.0\n",
      "pred_weight:  0.0\n",
      "pred_weight:  100.0\n",
      "pred_weight:  1000.0\n",
      "pred_weight:  10000.0\n",
      "pred_weight:  100000.0\n",
      "pred_weight:  1000000.0\n",
      "pred_weight:  10000000.0\n",
      "pred_weight:  100000000.0\n",
      "pred_weight:  1000000000.0\n",
      "pred_weight:  10000000000.0\n",
      "reg_weight:  100.0\n",
      "pred_weight:  0.0\n",
      "pred_weight:  100.0\n",
      "pred_weight:  1000.0\n",
      "pred_weight:  10000.0\n",
      "pred_weight:  100000.0\n",
      "pred_weight:  1000000.0\n",
      "pred_weight:  10000000.0\n",
      "pred_weight:  100000000.0\n",
      "pred_weight:  1000000000.0\n",
      "pred_weight:  10000000000.0\n",
      "reg_weight:  1000.0\n",
      "pred_weight:  0.0\n",
      "pred_weight:  100.0\n",
      "pred_weight:  1000.0\n",
      "pred_weight:  10000.0\n",
      "pred_weight:  100000.0\n",
      "pred_weight:  1000000.0\n",
      "pred_weight:  10000000.0\n",
      "pred_weight:  100000000.0\n",
      "pred_weight:  1000000000.0\n",
      "pred_weight:  10000000000.0\n",
      "reg_weight:  10000.0\n",
      "pred_weight:  0.0\n",
      "pred_weight:  100.0\n",
      "pred_weight:  1000.0\n",
      "pred_weight:  10000.0\n",
      "pred_weight:  100000.0\n",
      "pred_weight:  1000000.0\n",
      "pred_weight:  10000000.0\n",
      "pred_weight:  100000000.0\n",
      "pred_weight:  1000000000.0\n",
      "pred_weight:  10000000000.0\n",
      "reg_weight:  100000.0\n",
      "pred_weight:  0.0\n",
      "pred_weight:  100.0\n",
      "pred_weight:  1000.0\n",
      "pred_weight:  10000.0\n",
      "pred_weight:  100000.0\n",
      "pred_weight:  1000000.0\n",
      "pred_weight:  10000000.0\n",
      "pred_weight:  100000000.0\n",
      "pred_weight:  1000000000.0\n",
      "pred_weight:  10000000000.0\n",
      "init, 9\n",
      "reg_weight:  0.0\n",
      "pred_weight:  0.0\n",
      "pred_weight:  100.0\n",
      "pred_weight:  1000.0\n",
      "pred_weight:  10000.0\n",
      "pred_weight:  100000.0\n",
      "pred_weight:  1000000.0\n",
      "pred_weight:  10000000.0\n",
      "pred_weight:  100000000.0\n",
      "pred_weight:  1000000000.0\n",
      "pred_weight:  10000000000.0\n",
      "reg_weight:  100.0\n",
      "pred_weight:  0.0\n",
      "pred_weight:  100.0\n",
      "pred_weight:  1000.0\n",
      "pred_weight:  10000.0\n",
      "pred_weight:  100000.0\n",
      "pred_weight:  1000000.0\n",
      "pred_weight:  10000000.0\n",
      "pred_weight:  100000000.0\n",
      "pred_weight:  1000000000.0\n",
      "pred_weight:  10000000000.0\n",
      "reg_weight:  1000.0\n",
      "pred_weight:  0.0\n",
      "pred_weight:  100.0\n",
      "pred_weight:  1000.0\n",
      "pred_weight:  10000.0\n",
      "pred_weight:  100000.0\n",
      "pred_weight:  1000000.0\n",
      "pred_weight:  10000000.0\n",
      "pred_weight:  100000000.0\n",
      "pred_weight:  1000000000.0\n",
      "pred_weight:  10000000000.0\n",
      "reg_weight:  10000.0\n",
      "pred_weight:  0.0\n",
      "pred_weight:  100.0\n",
      "pred_weight:  1000.0\n",
      "pred_weight:  10000.0\n",
      "pred_weight:  100000.0\n",
      "pred_weight:  1000000.0\n",
      "pred_weight:  10000000.0\n",
      "pred_weight:  100000000.0\n",
      "pred_weight:  1000000000.0\n",
      "pred_weight:  10000000000.0\n",
      "reg_weight:  100000.0\n",
      "pred_weight:  0.0\n",
      "pred_weight:  100.0\n",
      "pred_weight:  1000.0\n",
      "pred_weight:  10000.0\n",
      "pred_weight:  100000.0\n",
      "pred_weight:  1000000.0\n",
      "pred_weight:  10000000.0\n",
      "pred_weight:  100000000.0\n",
      "pred_weight:  1000000000.0\n",
      "pred_weight:  10000000000.0\n"
     ]
    }
   ],
   "source": [
    "grad_objective_hinge_fast = grad(objective_hinge_fast, argnum = 0)\n",
    "grad_objective_logit_fast = grad(objective_logit_fast, argnum = 0)\n",
    "\n",
    "for init_idx in range(num_inits):\n",
    "    print \"init,\", init_idx\n",
    "    init_params[init_idx] = np.random.rand(params_size)\n",
    "    for i in range(reg_weights.shape[0]):\n",
    "        reg_weight = reg_weights[i]\n",
    "        print \"reg_weight: \", reg_weight\n",
    "        for j in range(pred_weights.shape[0]):    \n",
    "            pred_weight = pred_weights[j]\n",
    "            print \"pred_weight: \", pred_weight    \n",
    "            params_opt, obj, dict = fmin_l_bfgs_b(objective_logit_fast, x0 = init_params[init_idx], fprime = grad_objective_logit_fast, args = (X_train, y_train, latent_dim, pred_weight, opt, reg_weight), maxiter=3000, pgtol=1e-02)\n",
    "            params_opt_l_bfgs_b[init_idx, i, j] = params_opt\n",
    "            final_obj_val_l_bfgs_b[init_idx, i, j] = obj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_params_opt_l_bfgs_b = np.zeros((reg_weights.shape[0], pred_weights.shape[0], params_size))\n",
    "for i in range(reg_weights.shape[0]):\n",
    "    for j in range(pred_weights.shape[0]):    \n",
    "        best_init_idx = np.argmin(final_obj_val_l_bfgs_b[:, i, j])\n",
    "        best_params_opt_l_bfgs_b[i,j] = params_opt_l_bfgs_b[best_init_idx, i, j]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reg_weight:  0.0\n",
      "pred_weight:  0.0\n",
      "pred_weight:  100.0\n",
      "pred_weight:  1000.0\n",
      "pred_weight:  10000.0\n",
      "pred_weight:  100000.0\n",
      "pred_weight:  1000000.0\n",
      "pred_weight:  10000000.0\n",
      "pred_weight:  100000000.0\n",
      "pred_weight:  1000000000.0\n",
      "pred_weight:  10000000000.0\n",
      "reg_weight:  100.0\n",
      "pred_weight:  0.0\n",
      "pred_weight:  100.0\n",
      "pred_weight:  1000.0\n",
      "pred_weight:  10000.0\n",
      "pred_weight:  100000.0\n",
      "pred_weight:  1000000.0\n",
      "pred_weight:  10000000.0\n",
      "pred_weight:  100000000.0\n",
      "pred_weight:  1000000000.0\n",
      "pred_weight:  10000000000.0\n",
      "reg_weight:  1000.0\n",
      "pred_weight:  0.0\n",
      "pred_weight:  100.0\n",
      "pred_weight:  1000.0\n",
      "pred_weight:  10000.0\n",
      "pred_weight:  100000.0\n",
      "pred_weight:  1000000.0\n",
      "pred_weight:  10000000.0\n",
      "pred_weight:  100000000.0\n",
      "pred_weight:  1000000000.0\n",
      "pred_weight:  10000000000.0\n",
      "reg_weight:  10000.0\n",
      "pred_weight:  0.0\n",
      "pred_weight:  100.0\n",
      "pred_weight:  1000.0\n",
      "pred_weight:  10000.0\n",
      "pred_weight:  100000.0\n",
      "pred_weight:  1000000.0\n",
      "pred_weight:  10000000.0\n",
      "pred_weight:  100000000.0\n",
      "pred_weight:  1000000000.0\n",
      "pred_weight:  10000000000.0\n",
      "reg_weight:  100000.0\n",
      "pred_weight:  0.0\n",
      "pred_weight:  100.0\n",
      "pred_weight:  1000.0\n",
      "pred_weight:  10000.0\n",
      "pred_weight:  100000.0\n",
      "pred_weight:  1000000.0\n",
      "pred_weight:  10000000.0\n",
      "pred_weight:  100000000.0\n",
      "pred_weight:  1000000000.0\n",
      "pred_weight:  10000000000.0\n"
     ]
    }
   ],
   "source": [
    "test_acc_l_bfgs_b = np.zeros((reg_weights.shape[0], pred_weights.shape[0]))\n",
    "train_acc_l_bfgs_b = np.zeros((reg_weights.shape[0], pred_weights.shape[0]))\n",
    "pll_l_bfgs_b_test = np.zeros((reg_weights.shape[0], pred_weights.shape[0]))\n",
    "pll_l_bfgs_b_train = np.zeros((reg_weights.shape[0], pred_weights.shape[0]))\n",
    "ll_l_bfgs_b_test = np.zeros((reg_weights.shape[0], pred_weights.shape[0]))\n",
    "ll_l_bfgs_b_train = np.zeros((reg_weights.shape[0], pred_weights.shape[0]))\n",
    "\n",
    "for i in range(reg_weights.shape[0]):\n",
    "    reg_weight = reg_weights[i]\n",
    "    print \"reg_weight: \", reg_weight\n",
    "    for j in range(pred_weights.shape[0]):    \n",
    "        pred_weight = pred_weights[j]\n",
    "        print \"pred_weight: \", pred_weight    \n",
    " \n",
    "        params_opt = best_params_opt_l_bfgs_b[i,j]\n",
    "        \n",
    "        f, bias, cov_noise, w =  decode_parameters(params_opt, x_dim, latent_dim, opt)\n",
    "        x_train_transformed = transform(f, bias, cov_noise, X_train)\n",
    "        x_test_transformed = transform(f, bias, cov_noise, X_test)\n",
    "\n",
    "        \n",
    "        clf_pc = LogisticRegression()\n",
    "        clf_pc.coef_ = w[1:].reshape(1,  latent_dim)\n",
    "        clf_pc.intercept_ =  w[0]\n",
    "        clf_pc.classes_ = np.array([0, 1])\n",
    "        test_acc_l_bfgs_b[i,j] = clf_pc.score(x_test_transformed, y_test)\n",
    "        train_acc_l_bfgs_b[i,j] = clf_pc.score(x_train_transformed, y_train)\n",
    "\n",
    "        pll_l_bfgs_b_train[i,j] = compute_hinge_loss_fast(params_opt, X_train, y_train, latent_dim, opt)\n",
    "        pll_l_bfgs_b_test[i,j] = compute_hinge_loss_fast(params_opt, X_test, y_test, latent_dim, opt)\n",
    "\n",
    "        ll_l_bfgs_b_train[i,j] = compute_ll_fast(params_opt, X_train, latent_dim, opt)\n",
    "        ll_l_bfgs_b_test[i,j] = compute_ll_fast(params_opt, X_test, latent_dim, opt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.475, 0.525, 0.525, 0.525, 0.625, 0.65 , 0.675, 0.525, 0.525,\n",
       "        0.725],\n",
       "       [0.575, 0.525, 0.55 , 0.7  , 0.65 , 0.675, 0.625, 0.625, 0.6  ,\n",
       "        0.625],\n",
       "       [0.5  , 0.525, 0.55 , 0.65 , 0.65 , 0.675, 0.65 , 0.65 , 0.625,\n",
       "        0.625],\n",
       "       [0.525, 0.525, 0.525, 0.65 , 0.65 , 0.625, 0.65 , 0.65 , 0.65 ,\n",
       "        0.675],\n",
       "       [0.55 , 0.525, 0.525, 0.6  , 0.65 , 0.65 , 0.65 , 0.675, 0.625,\n",
       "        0.6  ]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_acc_l_bfgs_b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"params_logit_all_latent_{}_take_2.pkl\".format(latent_dim), 'wb') as f_save:\n",
    "    pickle.dump([best_params_opt_l_bfgs_b, final_obj_val_l_bfgs_b, test_acc_l_bfgs_b, train_acc_l_bfgs_b, pll_l_bfgs_b_train, pll_l_bfgs_b_test, ll_l_bfgs_b_train, ll_l_bfgs_b_test, reg_weights, pred_weights], f_save)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
