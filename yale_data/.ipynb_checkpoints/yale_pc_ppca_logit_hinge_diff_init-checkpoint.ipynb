{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import autograd.numpy as np\n",
    "from autograd import grad, hessian\n",
    "from autograd import elementwise_grad\n",
    "from scipy.optimize import fmin_l_bfgs_b, fmin_bfgs, fmin_cg, fmin_ncg\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.linalg import cho_factor, cho_solve, cholesky\n",
    "from autograd.scipy.linalg import solve_triangular\n",
    "from sklearn.decomposition import FactorAnalysis, PCA\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from autograd.misc.optimizers import adam\n",
    "import copy\n",
    "import glob\n",
    "import imageio\n",
    "import skimage\n",
    "from skimage import data, io, filters\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pickle\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_labels(filenames):\n",
    "    labels = np.zeros(len(filenames))\n",
    "    for i in range(len(filenames)):\n",
    "        if any(s in filenames[i] for s in ('sad', 'wink', 'surprised', 'sleepy', 'happy')):\n",
    "            labels[i] = 1\n",
    "    return labels\n",
    "\n",
    "\n",
    "img_arr_train = np.array([skimage.img_as_float(skimage.transform.rescale(imageio.imread(file),1.0 / 4.0)) for file in glob.glob('yale_train/*png')])\n",
    "img_arr_test = np.array([skimage.img_as_float(skimage.transform.rescale(imageio.imread(file),1.0 / 4.0)) for file in glob.glob('yale_test/*png')])\n",
    "X_train = np.reshape(img_arr_train, (img_arr_train.shape[0], img_arr_train.shape[1]*img_arr_train.shape[2]))\n",
    "X_test = np.reshape(img_arr_test, (img_arr_test.shape[0], img_arr_test.shape[1]*img_arr_test.shape[2]))\n",
    "y_train = get_labels(glob.glob('yale_train/*png'))\n",
    "y_test = get_labels(glob.glob('yale_test/*png'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "\n",
    "def hinge(x):\n",
    "    return -np.maximum(0.0, 1.0 - x)\n",
    "\n",
    "def objective_logit (params, x, y, latent_dim, lambda_e, opt): #check the order of arguments!\n",
    "    N = x.shape[0]\n",
    "    D = x.shape[1]\n",
    "    f, bias_x, cov_noise, w = decode_parameters(params, D, latent_dim, opt)\n",
    "        \n",
    "    cov_x = np.einsum(\"dl,ml->dm\",f,f) + cov_noise\n",
    "    #print cov_x.shape\n",
    "    sign, log_det_cov_x = np.linalg.slogdet(cov_x)\n",
    "    #print log_det_cov_x\n",
    "    temp1 = np.linalg.solve(cov_x, (x - bias_x).T)\n",
    "    unnorm_log_pdf_x = np.einsum(\"nd,dn->n\", x - bias_x, temp1)\n",
    "    ll = N*D*np.log(2*np.pi)/2 + log_det_cov_x*0.5*N + np.sum(unnorm_log_pdf_x)*0.5 \n",
    "\n",
    "    mean_z = np.einsum(\"dl,dn->nl\", f, temp1)\n",
    "    temp2 = np.einsum(\"l,nl->n\", w[1:], mean_z) + w[0]\n",
    "    log_bern_pdf_y = np.log(sigmoid(np.multiply((2*y-1),temp2)))\n",
    "    log_prior = 0 \n",
    "    lambda_r = 1\n",
    "    reg1 = lambda_r*np.sum(f**2)\n",
    "    reg2 = lambda_r*np.sum(w**2)\n",
    "    reg = reg1+reg2\n",
    "    ll = ll - lambda_e*np.sum(log_bern_pdf_y) - log_prior + reg\n",
    "    return ll\n",
    "\n",
    "def objective_logit_fast(params, x, y, latent_dim, lambda_e, opt, reg_weight): #check the order of arguments!\n",
    "    N = x.shape[0]\n",
    "    D = x.shape[1]\n",
    "    f, bias_x, cov_noise, w = decode_parameters_fast(params, D, latent_dim, opt)\n",
    "    L = f.shape[1]\n",
    "        \n",
    "    icn = (1.0 / cov_noise).reshape((-1, 1))\n",
    "    xn = (x - bias_x).T\n",
    "    Ax = icn * xn\n",
    "    Au = icn * f\n",
    "    C = np.eye(L) + np.dot(f.T, Au)\n",
    "    temp1 = np.dot(f.T, Ax)\n",
    "    temp1 = np.linalg.solve(C, temp1)\n",
    "    temp1 = np.dot(Au, temp1)\n",
    "    temp1 = Ax - temp1\n",
    "    sign, log_det_cov_x = np.linalg.slogdet(C)\n",
    "    log_det_cov_x += np.sum(np.log(cov_noise))\n",
    "    \n",
    "    unnorm_log_pdf_x = np.einsum(\"dn,dn->n\", xn, temp1)\n",
    "    \n",
    "    mean_z = np.dot(f.T, temp1).T\n",
    "    temp2 = np.einsum(\"l,nl->n\", w[1:], mean_z) + w[0]\n",
    "    log_bern_pdf_y = np.log(sigmoid(np.multiply((2*y-1),temp2)))\n",
    "    log_prior = 0 \n",
    "    reg = reg_weight*np.sum((f/np.sqrt(D))**2) + reg_weight*np.sum(w**2)\n",
    "    ll = N*D*np.log(2*np.pi)/2 + log_det_cov_x*0.5*N + np.sum(unnorm_log_pdf_x)*0.5 \n",
    "    obj = ll - lambda_e*np.sum(log_bern_pdf_y) - log_prior + reg\n",
    "    return obj\n",
    "\n",
    "def objective_logit_fast_f(params, w, x, y, latent_dim, lambda_e, opt, reg_weight): #check the order of arguments!\n",
    "    N = x.shape[0]\n",
    "    D = x.shape[1]\n",
    "    f, bias_x, cov_noise, _ = decode_parameters_fast(params, D, latent_dim, opt)\n",
    "    L = f.shape[1]\n",
    "        \n",
    "    icn = (1.0 / cov_noise).reshape((-1, 1))\n",
    "    xn = (x - bias_x).T\n",
    "    Ax = icn * xn\n",
    "    Au = icn * f\n",
    "    C = np.eye(L) + np.dot(f.T, Au)\n",
    "    temp1 = np.dot(f.T, Ax)\n",
    "    temp1 = np.linalg.solve(C, temp1)\n",
    "    temp1 = np.dot(Au, temp1)\n",
    "    temp1 = Ax - temp1\n",
    "    \n",
    "    sign, log_det_cov_x = np.linalg.slogdet(C)\n",
    "    log_det_cov_x += np.sum(np.log(cov_noise))\n",
    "    \n",
    "    unnorm_log_pdf_x = np.einsum(\"dn,dn->n\", xn, temp1)\n",
    "    \n",
    "    mean_z = np.dot(f.T, temp1).T\n",
    "    temp2 = np.einsum(\"l,nl->n\", w[1:], mean_z) + w[0]\n",
    "    log_bern_pdf_y = np.log(sigmoid(np.multiply((2*y-1),temp2)))\n",
    "    log_prior = 0 \n",
    "    reg = reg_weight*np.sum((f/np.sqrt(D))**2) + reg_weight*np.sum(w**2)\n",
    "    ll = N*D*np.log(2*np.pi)/2 + log_det_cov_x*0.5*N + np.sum(unnorm_log_pdf_x)*0.5 \n",
    "    obj = ll - lambda_e*np.sum(log_bern_pdf_y) - log_prior + reg\n",
    "    return obj\n",
    "\n",
    "\n",
    "def objective_hinge_fast(params, x, y, latent_dim, lambda_e, opt, reg_weight): #check the order of arguments!\n",
    "    N = x.shape[0]\n",
    "    D = x.shape[1]\n",
    "    f, bias_x, cov_noise, w = decode_parameters_fast(params, D, latent_dim, opt)\n",
    "    L = f.shape[1]\n",
    "        \n",
    "    icn = (1.0 / cov_noise).reshape((-1, 1))\n",
    "    xn = (x - bias_x).T\n",
    "    Ax = icn * xn\n",
    "    Au = icn * f\n",
    "    C = np.eye(L) + np.dot(f.T, Au)\n",
    "    temp1 = np.dot(f.T, Ax)\n",
    "    temp1 = np.linalg.solve(C, temp1)\n",
    "    temp1 = np.dot(Au, temp1)\n",
    "    temp1 = Ax - temp1\n",
    "    sign, log_det_cov_x = np.linalg.slogdet(C)\n",
    "    log_det_cov_x += np.sum(np.log(cov_noise))\n",
    "    \n",
    "    unnorm_log_pdf_x = np.einsum(\"dn,dn->n\", xn, temp1)\n",
    "    \n",
    "    mean_z = np.dot(f.T, temp1).T\n",
    "    temp2 = np.einsum(\"l,nl->n\", w[1:], mean_z) + w[0]\n",
    "    hinge_bern_pdf_y = hinge(np.multiply((2*y-1),temp2))\n",
    "    log_prior = 0 \n",
    "    reg = reg_weight*np.sum((f/np.sqrt(D))**2) + reg_weight*np.sum(w**2)\n",
    "    ll = N*D*np.log(2*np.pi)/2 + log_det_cov_x*0.5*N + np.sum(unnorm_log_pdf_x)*0.5 \n",
    "    obj = ll - lambda_e*np.sum(hinge_bern_pdf_y) - log_prior + reg\n",
    "    return obj\n",
    "\n",
    "def decode_parameters_fast(params, D, latent_dim, opt):\n",
    "    size_f = D*latent_dim\n",
    "    f =  params[:size_f]\n",
    "    f =  f.reshape(D, latent_dim)\n",
    "    bias_x = params[size_f:size_f+D]\n",
    "    if (opt==\"ppca\"):\n",
    "        var = params[size_f+D]\n",
    "        cov_noise= np.ones(D)*np.log(1+np.exp(var))\n",
    "        w = params[size_f+D+1:]\n",
    "    else:\n",
    "        var = params[size_f+D:size_f+D*2]\n",
    "        cov_noise = np.log(1+np.exp(var))\n",
    "        w = params[size_f+D*2:]\n",
    "    return f, bias_x, cov_noise, w\n",
    "\n",
    "def decode_parameters(params, D, latent_dim, opt):\n",
    "    size_f = D*latent_dim\n",
    "    f =  params[:size_f]\n",
    "    f =  f.reshape(D, latent_dim)\n",
    "    bias_x = params[size_f:size_f+D]\n",
    "    if (opt==\"ppca\"):\n",
    "        var = params[size_f+D]\n",
    "        cov_noise= np.diag(np.ones(D)*np.log(1+np.exp(var)))\n",
    "        w = params[size_f+D+1:]\n",
    "    else:\n",
    "        var = params[size_f+D:size_f+D*2]\n",
    "        cov_noise= np.diag(np.log(1+np.exp(var)))\n",
    "        w = params[size_f+D*2:]\n",
    "    return f, bias_x, cov_noise, w\n",
    "\n",
    "def transform(f, bias, cov_noise, x):\n",
    "    cov_x = np.einsum(\"dl,ml->dm\",f,f) + cov_noise\n",
    "    temp = np.linalg.solve(cov_x, (x - bias).T)\n",
    "    mean_z = np.einsum(\"dl,dn->nl\", f, temp)\n",
    "    return mean_z\n",
    "\n",
    "    \n",
    "def compute_ll(f,bias,cov_noise, x):\n",
    "    N = x.shape[0]\n",
    "    D = x.shape[1]\n",
    "    cov_x = np.einsum(\"dl,ml->dm\",f,f) + cov_noise\n",
    "    sign, log_det_cov_x = np.linalg.slogdet(cov_x)\n",
    "    temp1 = np.linalg.solve(cov_x, (x - bias).T)\n",
    "    ll = N*D*np.log(2*np.pi)/2\n",
    "    ll += log_det_cov_x*N/2\n",
    "    ll += np.sum(np.einsum(\"nd,dn->n\", x - bias, temp1))/2\n",
    "    return -ll\n",
    "\n",
    "def compute_ll_fast(params, x, latent_dim, opt):\n",
    "    N = x.shape[0]\n",
    "    D = x.shape[1]\n",
    "    f, bias_x, cov_noise, w = decode_parameters_fast(params, D, latent_dim, opt)\n",
    "    L = f.shape[1]\n",
    "        \n",
    "    icn = (1.0 / cov_noise).reshape((-1, 1))\n",
    "    xn = (x - bias_x).T\n",
    "    Ax = icn * xn\n",
    "    Au = icn * f\n",
    "    C = np.eye(L) + np.dot(f.T, Au)\n",
    "    temp1 = np.dot(f.T, Ax)\n",
    "    temp1 = np.linalg.solve(C, temp1)\n",
    "    temp1 = np.dot(Au, temp1)\n",
    "    temp1 = Ax - temp1\n",
    "    sign, log_det_cov_x = np.linalg.slogdet(C)\n",
    "    log_det_cov_x += np.sum(np.log(cov_noise))\n",
    "    \n",
    "    unnorm_log_pdf_x = np.einsum(\"dn,dn->n\", xn, temp1)\n",
    "    \n",
    "    ll = N*D*np.log(2*np.pi)/2 + log_det_cov_x*0.5*N + np.sum(unnorm_log_pdf_x)*0.5 \n",
    "    return -ll\n",
    "\n",
    "\n",
    "def compute_pll_logit(f, bias_x, cov_noise, w, x, y):\n",
    "    cov_x = np.einsum(\"dl,ml->dm\",f,f) + cov_noise\n",
    "    temp1 = np.linalg.solve(cov_x, (x - bias_x).T)\n",
    "    \n",
    "    mean_z = np.einsum(\"dl,dn->nl\", f, temp1)\n",
    "    temp2 = np.einsum(\"l,nl->n\", w[1:], mean_z) + w[0]\n",
    "    log_bern_pdf_y = np.log(sigmoid(np.multiply((2*y-1),temp2)))\n",
    "    return np.sum(log_bern_pdf_y)\n",
    "\n",
    "def compute_pll_logit_fast(params, x, y, latent_dim, opt):\n",
    "    N = x.shape[0]\n",
    "    D = x.shape[1]\n",
    "    f, bias_x, cov_noise, w = decode_parameters_fast(params, D, latent_dim, opt)\n",
    "    L = f.shape[1]\n",
    "        \n",
    "    icn = (1.0 / cov_noise).reshape((-1, 1))\n",
    "    xn = (x - bias_x).T\n",
    "    Ax = icn * xn\n",
    "    Au = icn * f\n",
    "    C = np.eye(L) + np.dot(f.T, Au)\n",
    "    temp1 = np.dot(f.T, Ax)\n",
    "    temp1 = np.linalg.solve(C, temp1)\n",
    "    temp1 = np.dot(Au, temp1)\n",
    "    temp1 = Ax - temp1\n",
    "    \n",
    "    mean_z = np.dot(f.T, temp1).T\n",
    "    temp2 = np.einsum(\"l,nl->n\", w[1:], mean_z) + w[0]\n",
    "    log_bern_pdf_y = np.log(sigmoid(np.multiply((2*y-1),temp2)))\n",
    "    return np.sum(log_bern_pdf_y)\n",
    "\n",
    "def compute_hinge_loss_fast(params, x, y, latent_dim, opt):\n",
    "    N = x.shape[0]\n",
    "    D = x.shape[1]\n",
    "    f, bias_x, cov_noise, w = decode_parameters_fast(params, D, latent_dim, opt)\n",
    "    L = f.shape[1]\n",
    "        \n",
    "    icn = (1.0 / cov_noise).reshape((-1, 1))\n",
    "    xn = (x - bias_x).T\n",
    "    Ax = icn * xn\n",
    "    Au = icn * f\n",
    "    C = np.eye(L) + np.dot(f.T, Au)\n",
    "    temp1 = np.dot(f.T, Ax)\n",
    "    temp1 = np.linalg.solve(C, temp1)\n",
    "    temp1 = np.dot(Au, temp1)\n",
    "    temp1 = Ax - temp1\n",
    "    \n",
    "    mean_z = np.dot(f.T, temp1).T\n",
    "    temp2 = np.einsum(\"l,nl->n\", w[1:], mean_z) + w[0]\n",
    "    \n",
    "    hinge_bern_pdf_y = hinge(np.multiply((2*y-1),temp2))\n",
    "    \n",
    "    return np.sum(hinge_bern_pdf_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "latent_dim = 2\n",
    "x_dim = X_train.shape[1]      \n",
    "\n",
    "params_size_logit_fa = x_dim*latent_dim + x_dim + x_dim + latent_dim + 1\n",
    "params_size_logit_ppca = x_dim*latent_dim + x_dim + 1 + latent_dim + 1\n",
    "opt = \"ppca\"\n",
    "if (opt == \"fa\"):\n",
    "    params_size = params_size_logit_fa\n",
    "else:\n",
    "    params_size = params_size_logit_ppca"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9304,)\n",
      "9304\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "init, 0\n",
      "reg_weight:  0.0\n",
      "pred_weight:  0.0\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-93e77d678998>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     23\u001b[0m             \u001b[0mpred_weight\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpred_weights\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m             \u001b[0;32mprint\u001b[0m \u001b[0;34m\"pred_weight: \"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpred_weight\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m             \u001b[0mparams_opt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfmin_l_bfgs_b\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobjective_logit_fast\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx0\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minit_params\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0minit_idx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfprime\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgrad_objective_logit_fast\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlatent_dim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpred_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreg_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmaxiter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpgtol\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1e-02\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m             \u001b[0mparams_opt_l_bfgs_b\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0minit_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparams_opt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m             \u001b[0mfinal_obj_val_l_bfgs_b\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0minit_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda2/lib/python2.7/site-packages/scipy/optimize/lbfgsb.pyc\u001b[0m in \u001b[0;36mfmin_l_bfgs_b\u001b[0;34m(func, x0, fprime, args, approx_grad, bounds, m, factr, pgtol, epsilon, iprint, maxfun, maxiter, disp, callback, maxls)\u001b[0m\n\u001b[1;32m    197\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m     res = _minimize_lbfgsb(fun, x0, args=args, jac=jac, bounds=bounds,\n\u001b[0;32m--> 199\u001b[0;31m                            **opts)\n\u001b[0m\u001b[1;32m    200\u001b[0m     d = {'grad': res['jac'],\n\u001b[1;32m    201\u001b[0m          \u001b[0;34m'task'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'message'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda2/lib/python2.7/site-packages/scipy/optimize/lbfgsb.pyc\u001b[0m in \u001b[0;36m_minimize_lbfgsb\u001b[0;34m(fun, x0, args, jac, bounds, disp, maxcor, ftol, gtol, eps, maxfun, maxiter, iprint, callback, maxls, **unknown_options)\u001b[0m\n\u001b[1;32m    333\u001b[0m             \u001b[0;31m# until the completion of the current minimization iteration.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    334\u001b[0m             \u001b[0;31m# Overwrite f and g:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 335\u001b[0;31m             \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc_and_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    336\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mtask_str\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mb'NEW_X'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    337\u001b[0m             \u001b[0;31m# new iteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda2/lib/python2.7/site-packages/scipy/optimize/lbfgsb.pyc\u001b[0m in \u001b[0;36mfunc_and_grad\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m    284\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mfunc_and_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    285\u001b[0m             \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 286\u001b[0;31m             \u001b[0mg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjac\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    287\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    288\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda2/lib/python2.7/site-packages/autograd/wrap_util.pyc\u001b[0m in \u001b[0;36mnary_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     18\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m                 \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0margnum\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0munary_operator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0munary_f\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mnary_op_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mnary_op_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mnary_f\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mnary_operator\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda2/lib/python2.7/site-packages/autograd/differential_operators.pyc\u001b[0m in \u001b[0;36mgrad\u001b[0;34m(fun, x)\u001b[0m\n\u001b[1;32m     26\u001b[0m         raise TypeError(\"Grad only applies to real scalar-output functions. \"\n\u001b[1;32m     27\u001b[0m                         \"Try jacobian or elementwise_grad.\")\n\u001b[0;32m---> 28\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mvjp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvspace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mans\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mones\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;34m@\u001b[0m\u001b[0munary_to_nary\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda2/lib/python2.7/site-packages/autograd/core.pyc\u001b[0m in \u001b[0;36mvjp\u001b[0;34m(g)\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mvjp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mreturn\u001b[0m \u001b[0mvspace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m         \u001b[0;32mdef\u001b[0m \u001b[0mvjp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mreturn\u001b[0m \u001b[0mbackward_pass\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend_node\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mvjp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda2/lib/python2.7/site-packages/autograd/core.pyc\u001b[0m in \u001b[0;36mbackward_pass\u001b[0;34m(g, end_node)\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0mingrads\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvjp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutgrad\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mparent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mingrad\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparents\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mingrads\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m             \u001b[0moutgrads\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mparent\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0madd_outgrads\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutgrads\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparent\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mingrad\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0moutgrad\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda2/lib/python2.7/site-packages/autograd/core.pyc\u001b[0m in \u001b[0;36madd_outgrads\u001b[0;34m(prev_g_flagged, g)\u001b[0m\n\u001b[1;32m    163\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0msparse_add\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprev_g_mutable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    164\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 165\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mvs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprev_g\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    166\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    167\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0msparse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda2/lib/python2.7/site-packages/autograd/tracer.pyc\u001b[0m in \u001b[0;36mf_wrapped\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     46\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mnew_box\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mans\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 48\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mf_raw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     49\u001b[0m     \u001b[0mf_wrapped\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfun\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf_raw\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m     \u001b[0mf_wrapped\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_is_autograd_primitive\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda2/lib/python2.7/site-packages/autograd/core.pyc\u001b[0m in \u001b[0;36madd\u001b[0;34m(self, x_prev, x_new)\u001b[0m\n\u001b[1;32m    194\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_mut_add\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_prev\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_new\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    195\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mprimitive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 196\u001b[0;31m     \u001b[0;32mdef\u001b[0m \u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_prev\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_new\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_add\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_prev\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_new\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    197\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mprimitive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mscalar_mul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_scalar_mul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda2/lib/python2.7/site-packages/autograd/core.pyc\u001b[0m in \u001b[0;36m_add\u001b[0;34m(self, x, y)\u001b[0m\n\u001b[1;32m    202\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcovector\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m            \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_covector\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 204\u001b[0;31m     \u001b[0;32mdef\u001b[0m \u001b[0m_add\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m        \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    205\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_mut_add\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m    \u001b[0mx\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m;\u001b[0m \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    206\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_scalar_mul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "reg_weights = np.array([0, 1e2, 1e3, 1e4, 1e5])\n",
    "#reg_weights = np.array([1e3])\n",
    "\n",
    "pred_weights = np.array([0, 1e2, 1e3,1e4, 1e5, 1e6, 1e7, 1e8, 1e9, 1e10])\n",
    "#pred_weights = np.array([1e4])\n",
    "\n",
    "num_inits = 10\n",
    "\n",
    "params_opt_l_bfgs_b = np.zeros((num_inits, reg_weights.shape[0], pred_weights.shape[0], params_size))\n",
    "final_obj_val_l_bfgs_b = np.zeros((num_inits, reg_weights.shape[0], pred_weights.shape[0]))\n",
    "init_params = np.zeros((num_inits, params_size))\n",
    "\n",
    "grad_objective_hinge_fast = grad(objective_hinge_fast, argnum = 0)\n",
    "grad_objective_logit_fast = grad(objective_logit_fast, argnum = 0)\n",
    "\n",
    "for init_idx in range(num_inits):\n",
    "    print \"init,\", init_idx\n",
    "    init_params[init_idx] = np.random.rand(params_size)\n",
    "    for i in range(reg_weights.shape[0]):\n",
    "        reg_weight = reg_weights[i]\n",
    "        print \"reg_weight: \", reg_weight\n",
    "        for j in range(pred_weights.shape[0]):    \n",
    "            pred_weight = pred_weights[j]\n",
    "            print \"pred_weight: \", pred_weight    \n",
    "            params_opt, obj, dict = fmin_l_bfgs_b(objective_logit_fast, x0 = init_params[init_idx], fprime = grad_objective_logit_fast, args = (X_train, y_train, latent_dim, pred_weight, opt, reg_weight), maxiter=3000, pgtol=1e-02)\n",
    "            params_opt_l_bfgs_b[init_idx, i, j] = params_opt\n",
    "            final_obj_val_l_bfgs_b[init_idx, i, j] = obj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg_weights = np.array([100])\n",
    "pred_weights = np.array([10000, 100000])\n",
    "\n",
    "num_inits = 10\n",
    "\n",
    "params_opt_l_bfgs_b = np.zeros((num_inits, reg_weights.shape[0], pred_weights.shape[0], params_size))\n",
    "final_obj_val_l_bfgs_b = np.zeros((num_inits, reg_weights.shape[0], pred_weights.shape[0]))\n",
    "init_params = np.zeros((num_inits, params_size))\n",
    "\n",
    "grad_objective_logit_fast = grad(objective_logit_fast_f, argnum = 0)\n",
    "w_guess =  np.ones(latent_dim+1)\n",
    "w_guess[0] = 0\n",
    "for init_idx in range(num_inits):\n",
    "    print \"init,\", init_idx\n",
    "    init_params[init_idx] = np.random.rand(params_size)\n",
    "    for i in range(reg_weights.shape[0]):\n",
    "        reg_weight = reg_weights[i]\n",
    "        print \"reg_weight: \", reg_weight\n",
    "        for j in range(pred_weights.shape[0]):    \n",
    "            pred_weight = pred_weights[j]\n",
    "            print \"pred_weight: \", pred_weight    \n",
    "            params_opt, obj, dict = fmin_l_bfgs_b(objective_logit_fast_f, x0 = init_params[init_idx], fprime = grad_objective_logit_fast, args = (w_guess, X_train, y_train, latent_dim, pred_weight, opt, reg_weight), maxiter=3000, pgtol=1e-02)\n",
    "            params_opt_l_bfgs_b[init_idx, i, j] = params_opt\n",
    "            final_obj_val_l_bfgs_b[init_idx, i, j] = obj\n",
    "params_opt_l_bfgs_b[:,:,:,x_dim*latent_dim+x_dim+1:] = w_guess\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('init_params.pkl') as f:  \n",
    "    [init_params] = pickle.load(f)\n",
    "pred_weight = 0\n",
    "reg_weight = 1\n",
    "grad_objective_logit_fast = grad(objective_logit_fast, argnum = 0)\n",
    "print objective_logit_fast(init_params, X_train, y_train, latent_dim, pred_weight, opt, reg_weight)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "262974.93568790774"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params_opt, obj, dict = fmin_l_bfgs_b(objective_logit_fast, x0 = init_params, fprime = grad_objective_logit_fast, args = (X_train, y_train, latent_dim, pred_weight, opt, reg_weight), maxiter=3000, pgtol=1e-02)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_params_opt_l_bfgs_b = np.zeros((reg_weights.shape[0], pred_weights.shape[0], params_size))\n",
    "for i in range(reg_weights.shape[0]):\n",
    "    for j in range(pred_weights.shape[0]):    \n",
    "        best_init_idx = np.argmin(final_obj_val_l_bfgs_b[:5, i, j])\n",
    "        best_params_opt_l_bfgs_b[i,j] = params_opt_l_bfgs_b[best_init_idx, i, j]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_acc_l_bfgs_b = np.zeros((reg_weights.shape[0], pred_weights.shape[0]))\n",
    "train_acc_l_bfgs_b = np.zeros((reg_weights.shape[0], pred_weights.shape[0]))\n",
    "pll_l_bfgs_b_test = np.zeros((reg_weights.shape[0], pred_weights.shape[0]))\n",
    "pll_l_bfgs_b_train = np.zeros((reg_weights.shape[0], pred_weights.shape[0]))\n",
    "ll_l_bfgs_b_test = np.zeros((reg_weights.shape[0], pred_weights.shape[0]))\n",
    "ll_l_bfgs_b_train = np.zeros((reg_weights.shape[0], pred_weights.shape[0]))\n",
    "\n",
    "for i in range(reg_weights.shape[0]):\n",
    "    reg_weight = reg_weights[i]\n",
    "    print \"reg_weight: \", reg_weight\n",
    "    for j in range(pred_weights.shape[0]):    \n",
    "        pred_weight = pred_weights[j]\n",
    "        print \"pred_weight: \", pred_weight    \n",
    " \n",
    "        params_opt = best_params_opt_l_bfgs_b[i,j]\n",
    "        \n",
    "        f, bias, cov_noise, w =  decode_parameters(params_opt, x_dim, latent_dim, opt)\n",
    "        x_train_transformed = transform(f, bias, cov_noise, X_train)\n",
    "        x_test_transformed = transform(f, bias, cov_noise, X_test)\n",
    "        \n",
    "        \n",
    "        clf_pc = LogisticRegression()\n",
    "        clf_pc.coef_ = w[1:].reshape(1,  latent_dim)\n",
    "        clf_pc.intercept_ =  w[0]\n",
    "        clf_pc.classes_ = np.array([0, 1])\n",
    "        test_acc_l_bfgs_b[i,j] = clf_pc.score(x_test_transformed, y_test)\n",
    "        train_acc_l_bfgs_b[i,j] = clf_pc.score(x_train_transformed, y_train)\n",
    "\n",
    "        pll_l_bfgs_b_train[i,j] = compute_pll_logit_fast(params_opt, X_train, y_train, latent_dim, opt)\n",
    "        pll_l_bfgs_b_test[i,j] = compute_pll_logit_fast(params_opt, X_test, y_test, latent_dim, opt)\n",
    "\n",
    "        ll_l_bfgs_b_train[i,j] = compute_ll_fast(params_opt, X_train, latent_dim, opt)\n",
    "        ll_l_bfgs_b_test[i,j] = compute_ll_fast(params_opt, X_test, latent_dim, opt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_acc_l_bfgs_b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"ppca_fixed_w_params_latent_{}.pkl\".format(latent_dim), 'wb') as f_save:\n",
    "    pickle.dump([params_opt_l_bfgs_b, final_obj_val_l_bfgs_b, best_params_opt_l_bfgs_b, opt], f_save)\n",
    "with open(\"ppca_fixed_w_metrics_latent_{}.pkl\".format(latent_dim), 'wb') as f_save:\n",
    "    pickle.dump([test_acc_l_bfgs_b, train_acc_l_bfgs_b, pll_l_bfgs_b_train, pll_l_bfgs_b_test, ll_l_bfgs_b_train, ll_l_bfgs_b_test, reg_weights, pred_weights], f_save)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_obj_val_l_bfgs_b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"params_logit_all_latent_{}_take_3.pkl\".format(latent_dim), 'wb') as f_save:\n",
    "    pickle.dump([best_params_opt_l_bfgs_b, final_obj_val_l_bfgs_b, test_acc_l_bfgs_b, train_acc_l_bfgs_b, pll_l_bfgs_b_train, pll_l_bfgs_b_test, ll_l_bfgs_b_train, ll_l_bfgs_b_test, reg_weights, pred_weights], f_save)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
