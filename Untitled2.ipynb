{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import autograd.numpy as np\n",
    "from autograd import grad, hessian\n",
    "from autograd import elementwise_grad\n",
    "from scipy.optimize import fmin_l_bfgs_b, fmin_bfgs, fmin_cg, fmin_ncg\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.linalg import cho_factor, cho_solve, cholesky\n",
    "from autograd.scipy.linalg import solve_triangular\n",
    "from sklearn.decomposition import FactorAnalysis, PCA\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from autograd.misc.optimizers import adam\n",
    "import copy\n",
    "import glob\n",
    "import imageio\n",
    "import skimage\n",
    "from skimage import data, io, filters\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pickle\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda2/lib/python2.7/site-packages/skimage/transform/_warps.py:24: UserWarning: The default multichannel argument (None) is deprecated.  Please specify either True or False explicitly.  multichannel will default to False starting with release 0.16.\n",
      "  warn('The default multichannel argument (None) is deprecated.  Please '\n",
      "/anaconda2/lib/python2.7/site-packages/skimage/transform/_warps.py:105: UserWarning: The default mode, 'constant', will be changed to 'reflect' in skimage 0.15.\n",
      "  warn(\"The default mode, 'constant', will be changed to 'reflect' in \"\n",
      "/anaconda2/lib/python2.7/site-packages/skimage/transform/_warps.py:110: UserWarning: Anti-aliasing will be enabled by default in skimage 0.15 to avoid aliasing artifacts when down-sampling images.\n",
      "  warn(\"Anti-aliasing will be enabled by default in skimage 0.15 to \"\n"
     ]
    }
   ],
   "source": [
    "def get_labels(filenames):\n",
    "    labels = np.zeros(len(filenames))\n",
    "    for i in range(len(filenames)):\n",
    "        if any(s in filenames[i] for s in ('sad', 'wink', 'surprised', 'sleepy', 'happy')):\n",
    "            labels[i] = 1\n",
    "    return labels\n",
    "\n",
    "\n",
    "img_arr_train = np.array([skimage.img_as_float(skimage.transform.rescale(imageio.imread(file),1.0 / 4.0)) for file in glob.glob('yale_train/*png')])\n",
    "img_arr_test = np.array([skimage.img_as_float(skimage.transform.rescale(imageio.imread(file),1.0 / 4.0)) for file in glob.glob('yale_test/*png')])\n",
    "X_train = np.reshape(img_arr_train, (img_arr_train.shape[0], img_arr_train.shape[1]*img_arr_train.shape[2]))\n",
    "X_test = np.reshape(img_arr_test, (img_arr_test.shape[0], img_arr_test.shape[1]*img_arr_test.shape[2]))\n",
    "y_train = get_labels(glob.glob('yale_train/*png'))\n",
    "y_test = get_labels(glob.glob('yale_test/*png'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "\n",
    "def hinge(x):\n",
    "    return -np.maximum(0.0, 1.0 - x)\n",
    "\n",
    "def objective_logit (params, x, y, latent_dim, lambda_e, opt): #check the order of arguments!\n",
    "    N = x.shape[0]\n",
    "    D = x.shape[1]\n",
    "    f, bias_x, cov_noise, w = decode_parameters(params, D, latent_dim, opt)\n",
    "        \n",
    "    cov_x = np.einsum(\"dl,ml->dm\",f,f) + cov_noise\n",
    "    #print cov_x.shape\n",
    "    sign, log_det_cov_x = np.linalg.slogdet(cov_x)\n",
    "    #print log_det_cov_x\n",
    "    temp1 = np.linalg.solve(cov_x, (x - bias_x).T)\n",
    "    unnorm_log_pdf_x = np.einsum(\"nd,dn->n\", x - bias_x, temp1)\n",
    "    ll = N*D*np.log(2*np.pi)/2 + log_det_cov_x*0.5*N + np.sum(unnorm_log_pdf_x)*0.5 \n",
    "\n",
    "    mean_z = np.einsum(\"dl,dn->nl\", f, temp1)\n",
    "    temp2 = np.einsum(\"l,nl->n\", w[1:], mean_z) + w[0]\n",
    "    log_bern_pdf_y = np.log(sigmoid(np.multiply((2*y-1),temp2)))\n",
    "    log_prior = 0 \n",
    "    lambda_r = 1\n",
    "    reg1 = lambda_r*np.sum(f**2)\n",
    "    reg2 = lambda_r*np.sum(w**2)\n",
    "    reg = reg1+reg2\n",
    "    ll = ll - lambda_e*np.sum(log_bern_pdf_y) - log_prior + reg\n",
    "    return ll\n",
    "\n",
    "def objective_logit_fast(params, x, y, latent_dim, lambda_e, opt, reg_weight): #check the order of arguments!\n",
    "    N = x.shape[0]\n",
    "    D = x.shape[1]\n",
    "    f, bias_x, cov_noise, w = decode_parameters_fast(params, D, latent_dim, opt)\n",
    "    L = f.shape[1]\n",
    "        \n",
    "    icn = (1.0 / cov_noise).reshape((-1, 1))\n",
    "    xn = (x - bias_x).T\n",
    "    Ax = icn * xn\n",
    "    Au = icn * f\n",
    "    C = np.eye(L) + np.dot(f.T, Au)\n",
    "    temp1 = np.dot(f.T, Ax)\n",
    "    temp1 = np.linalg.solve(C, temp1)\n",
    "    temp1 = np.dot(Au, temp1)\n",
    "    temp1 = Ax - temp1\n",
    "    sign, log_det_cov_x = np.linalg.slogdet(C)\n",
    "    log_det_cov_x += np.sum(np.log(cov_noise))\n",
    "    \n",
    "    unnorm_log_pdf_x = np.einsum(\"dn,dn->n\", xn, temp1)\n",
    "    \n",
    "    mean_z = np.dot(f.T, temp1).T\n",
    "    temp2 = np.einsum(\"l,nl->n\", w[1:], mean_z) + w[0]\n",
    "    log_bern_pdf_y = np.log(sigmoid(np.multiply((2*y-1),temp2)))\n",
    "    log_prior = 0 \n",
    "    reg = reg_weight*np.sum((f/np.sqrt(D))**2) + reg_weight*np.sum(w**2)\n",
    "    ll = N*D*np.log(2*np.pi)/2 + log_det_cov_x*0.5*N + np.sum(unnorm_log_pdf_x)*0.5 \n",
    "    obj = ll - lambda_e*np.sum(log_bern_pdf_y) - log_prior + reg\n",
    "    return obj\n",
    "\n",
    "def objective_hinge_fast(params, x, y, latent_dim, lambda_e, opt, reg_weight): #check the order of arguments!\n",
    "    N = x.shape[0]\n",
    "    D = x.shape[1]\n",
    "    f, bias_x, cov_noise, w = decode_parameters_fast(params, D, latent_dim, opt)\n",
    "    L = f.shape[1]\n",
    "        \n",
    "    icn = (1.0 / cov_noise).reshape((-1, 1))\n",
    "    xn = (x - bias_x).T\n",
    "    Ax = icn * xn\n",
    "    Au = icn * f\n",
    "    C = np.eye(L) + np.dot(f.T, Au)\n",
    "    temp1 = np.dot(f.T, Ax)\n",
    "    temp1 = np.linalg.solve(C, temp1)\n",
    "    temp1 = np.dot(Au, temp1)\n",
    "    temp1 = Ax - temp1\n",
    "    sign, log_det_cov_x = np.linalg.slogdet(C)\n",
    "    log_det_cov_x += np.sum(np.log(cov_noise))\n",
    "    \n",
    "    unnorm_log_pdf_x = np.einsum(\"dn,dn->n\", xn, temp1)\n",
    "    \n",
    "    mean_z = np.dot(f.T, temp1).T\n",
    "    temp2 = np.einsum(\"l,nl->n\", w[1:], mean_z) + w[0]\n",
    "    hinge_bern_pdf_y = hinge(np.multiply((2*y-1),temp2))\n",
    "    log_prior = 0 \n",
    "    reg = reg_weight*np.sum((f/np.sqrt(D))**2) + reg_weight*np.sum(w**2)\n",
    "    ll = N*D*np.log(2*np.pi)/2 + log_det_cov_x*0.5*N + np.sum(unnorm_log_pdf_x)*0.5 \n",
    "    obj = ll - lambda_e*np.sum(hinge_bern_pdf_y) - log_prior + reg\n",
    "    return obj\n",
    "\n",
    "def decode_parameters_fast(params, D, latent_dim, opt):\n",
    "    size_f = D*latent_dim\n",
    "    f =  params[:size_f]\n",
    "    #f = f*np.array([0,1]) + np.array([1,0])\n",
    "    f =  f.reshape(D, latent_dim)\n",
    "    bias_x = params[size_f:size_f+D]\n",
    "    if (opt==\"ppca\"):\n",
    "        var = params[size_f+D]\n",
    "        cov_noise= np.ones(D)*np.log(1+np.exp(var))\n",
    "        #cov_noise= np.diag(np.ones(D)*np.exp(var))\n",
    "        w = params[size_f+D+1:]\n",
    "    else:\n",
    "        var = params[size_f+D:size_f+D*2]\n",
    "        cov_noise = np.log(1+np.exp(var))\n",
    "        w = params[size_f+D*2:]\n",
    "    return f, bias_x, cov_noise, w\n",
    "\n",
    "def decode_parameters(params, D, latent_dim, opt):\n",
    "    size_f = D*latent_dim\n",
    "    f =  params[:size_f]\n",
    "    #f = f*np.array([0,1]) + np.array([1,0])\n",
    "    f =  f.reshape(D, latent_dim)\n",
    "    bias_x = params[size_f:size_f+D]\n",
    "    if (opt==\"ppca\"):\n",
    "        var = params[size_f+D]\n",
    "        cov_noise= np.diag(np.ones(D)*np.log(1+np.exp(var)))\n",
    "        #cov_noise= np.diag(np.ones(D)*np.exp(var))\n",
    "        w = params[size_f+D+1:]\n",
    "    else:\n",
    "        var = params[size_f+D:size_f+D*2]\n",
    "        cov_noise= np.diag(np.log(1+np.exp(var)))\n",
    "        w = params[size_f+D*2:]\n",
    "    return f, bias_x, cov_noise, w\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "def compute_ll(f,bias,cov_noise, x):\n",
    "    N = x.shape[0]\n",
    "    D = x.shape[1]\n",
    "    cov_x = np.einsum(\"dl,ml->dm\",f,f) + cov_noise\n",
    "    sign, log_det_cov_x = np.linalg.slogdet(cov_x)\n",
    "    temp1 = np.linalg.solve(cov_x, (x - bias).T)\n",
    "    ll = N*D*np.log(2*np.pi)/2\n",
    "    ll += log_det_cov_x*N/2\n",
    "    ll += np.sum(np.einsum(\"nd,dn->n\", x - bias, temp1))/2\n",
    "    return -ll\n",
    "\n",
    "def compute_ll_fast(params, x, latent_dim, opt):\n",
    "    N = x.shape[0]\n",
    "    D = x.shape[1]\n",
    "    f, bias_x, cov_noise, w = decode_parameters_fast(params, D, latent_dim, opt)\n",
    "    L = f.shape[1]\n",
    "        \n",
    "    icn = (1.0 / cov_noise).reshape((-1, 1))\n",
    "    xn = (x - bias_x).T\n",
    "    Ax = icn * xn\n",
    "    Au = icn * f\n",
    "    C = np.eye(L) + np.dot(f.T, Au)\n",
    "    temp1 = np.dot(f.T, Ax)\n",
    "    temp1 = np.linalg.solve(C, temp1)\n",
    "    temp1 = np.dot(Au, temp1)\n",
    "    temp1 = Ax - temp1\n",
    "    sign, log_det_cov_x = np.linalg.slogdet(C)\n",
    "    log_det_cov_x += np.sum(np.log(cov_noise))\n",
    "    \n",
    "    unnorm_log_pdf_x = np.einsum(\"dn,dn->n\", xn, temp1)\n",
    "    \n",
    "    ll = N*D*np.log(2*np.pi)/2 + log_det_cov_x*0.5*N + np.sum(unnorm_log_pdf_x)*0.5 \n",
    "    return -ll\n",
    "\n",
    "\n",
    "def compute_pll_logit(f, bias_x, cov_noise, w, x, y):\n",
    "    cov_x = np.einsum(\"dl,ml->dm\",f,f) + cov_noise\n",
    "    temp1 = np.linalg.solve(cov_x, (x - bias_x).T)\n",
    "    \n",
    "    mean_z = np.einsum(\"dl,dn->nl\", f, temp1)\n",
    "    temp2 = np.einsum(\"l,nl->n\", w[1:], mean_z) + w[0]\n",
    "    log_bern_pdf_y = np.log(sigmoid(np.multiply((2*y-1),temp2)))\n",
    "    return np.sum(log_bern_pdf_y)\n",
    "\n",
    "def compute_pll_logit_fast(params, x, y, latent_dim, opt):\n",
    "    N = x.shape[0]\n",
    "    D = x.shape[1]\n",
    "    f, bias_x, cov_noise, w = decode_parameters_fast(params, D, latent_dim, opt)\n",
    "    L = f.shape[1]\n",
    "        \n",
    "    icn = (1.0 / cov_noise).reshape((-1, 1))\n",
    "    xn = (x - bias_x).T\n",
    "    Ax = icn * xn\n",
    "    Au = icn * f\n",
    "    C = np.eye(L) + np.dot(f.T, Au)\n",
    "    temp1 = np.dot(f.T, Ax)\n",
    "    temp1 = np.linalg.solve(C, temp1)\n",
    "    temp1 = np.dot(Au, temp1)\n",
    "    temp1 = Ax - temp1\n",
    "    \n",
    "    mean_z = np.dot(f.T, temp1).T\n",
    "    temp2 = np.einsum(\"l,nl->n\", w[1:], mean_z) + w[0]\n",
    "    log_bern_pdf_y = np.log(sigmoid(np.multiply((2*y-1),temp2)))\n",
    "    return np.sum(log_bern_pdf_y)\n",
    "\n",
    "def compute_hinge_loss_fast(params, x, y, latent_dim, opt):\n",
    "    N = x.shape[0]\n",
    "    D = x.shape[1]\n",
    "    f, bias_x, cov_noise, w = decode_parameters_fast(params, D, latent_dim, opt)\n",
    "    L = f.shape[1]\n",
    "        \n",
    "    icn = (1.0 / cov_noise).reshape((-1, 1))\n",
    "    xn = (x - bias_x).T\n",
    "    Ax = icn * xn\n",
    "    Au = icn * f\n",
    "    C = np.eye(L) + np.dot(f.T, Au)\n",
    "    temp1 = np.dot(f.T, Ax)\n",
    "    temp1 = np.linalg.solve(C, temp1)\n",
    "    temp1 = np.dot(Au, temp1)\n",
    "    temp1 = Ax - temp1\n",
    "    \n",
    "    mean_z = np.dot(f.T, temp1).T\n",
    "    temp2 = np.einsum(\"l,nl->n\", w[1:], mean_z) + w[0]\n",
    "    \n",
    "    hinge_bern_pdf_y = hinge(np.multiply((2*y-1),temp2))\n",
    "    \n",
    "    return np.sum(hinge_bern_pdf_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "latent_dim = 2\n",
    "x_dim = X_train.shape[1]      \n",
    "params_size = x_dim*latent_dim + x_dim + 1 + latent_dim + 1\n",
    "opt = \"ppca\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg_weights = np.array([0, 1e2, 1e3, 1e4, 1e5])\n",
    "#reg_weights = np.array([1e3])\n",
    "\n",
    "pred_weights = np.array([0, 1e2, 1e3,1e4, 1e5, 1e6, 1e7, 1e8, 1e9, 1e10])\n",
    "#pred_weights = np.array([1e4])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('params_latent_2.pkl') as f:  \n",
    "    a = pickle.load(f)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ True,  True,  True, ...,  True,  True,  True]])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a[0][0,0] == np.zeros((a[0][0,0].shape))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'final_obj_val_l_bfgs_b' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-314d63a6c389>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreg_weights\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred_weights\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m         \u001b[0mbest_init_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfinal_obj_val_l_bfgs_b\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m         \u001b[0mbest_params_opt_l_bfgs_b\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparams_opt_l_bfgs_b\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbest_init_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'final_obj_val_l_bfgs_b' is not defined"
     ]
    }
   ],
   "source": [
    "best_params_opt_l_bfgs_b = np.zeros((reg_weights.shape[0], pred_weights.shape[0], params_size))\n",
    "for i in range(reg_weights.shape[0]):\n",
    "    for j in range(pred_weights.shape[0]):    \n",
    "        best_init_idx = np.argmin(final_obj_val_l_bfgs_b[:, i, j])\n",
    "        best_params_opt_l_bfgs_b[i,j] = params_opt_l_bfgs_b[best_init_idx, i, j]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_acc_l_bfgs_b = np.zeros((reg_weights.shape[0], pred_weights.shape[0]))\n",
    "train_acc_l_bfgs_b = np.zeros((reg_weights.shape[0], pred_weights.shape[0]))\n",
    "pll_l_bfgs_b_test = np.zeros((reg_weights.shape[0], pred_weights.shape[0]))\n",
    "pll_l_bfgs_b_train = np.zeros((reg_weights.shape[0], pred_weights.shape[0]))\n",
    "ll_l_bfgs_b_test = np.zeros((reg_weights.shape[0], pred_weights.shape[0]))\n",
    "ll_l_bfgs_b_train = np.zeros((reg_weights.shape[0], pred_weights.shape[0]))\n",
    "\n",
    "for i in range(reg_weights.shape[0]):\n",
    "    reg_weight = reg_weights[i]\n",
    "    print \"reg_weight: \", reg_weight\n",
    "    for j in range(pred_weights.shape[0]):    \n",
    "        pred_weight = pred_weights[j]\n",
    "        print \"pred_weight: \", pred_weight    \n",
    " \n",
    "        params_opt = best_params_opt_l_bfgs_b[i,j]\n",
    "        \n",
    "        f, bias, cov_noise, w =  decode_parameters(params_opt, x_dim, latent_dim, opt)\n",
    "        x_train_transformed = transform(f, bias, cov_noise, X_train)\n",
    "        x_test_transformed = transform(f, bias, cov_noise, X_test)\n",
    "\n",
    "        \n",
    "        clf_pc = LogisticRegression()\n",
    "        clf_pc.coef_ = w[1:].reshape(1,  latent_dim)\n",
    "        clf_pc.intercept_ =  w[0]\n",
    "        clf_pc.classes_ = np.array([0, 1])\n",
    "        test_acc_l_bfgs_b[i,j] = clf_pc.score(x_test_transformed, y_test)\n",
    "        train_acc_l_bfgs_b[i,j] = clf_pc.score(x_train_transformed, y_train)\n",
    "\n",
    "        pll_l_bfgs_b_train[i,j] = compute_hinge_loss_fast(params_opt, X_train, y_train, latent_dim, opt)\n",
    "        pll_l_bfgs_b_test[i,j] = compute_hinge_loss_fast(params_opt, X_test, y_test, latent_dim, opt)\n",
    "\n",
    "        ll_l_bfgs_b_train[i,j] = compute_ll_fast(params_opt, X_train, latent_dim, opt)\n",
    "        ll_l_bfgs_b_test[i,j] = compute_ll_fast(params_opt, X_test, latent_dim, opt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"params_hinge_1000_all_latent_{}.pkl\".format(latent_dim), 'wb') as f_save:\n",
    "    pickle.dump([best_params_opt_l_bfgs_b, final_obj_val_l_bfgs_b, test_acc_l_bfgs_b, train_acc_l_bfgs_b, pll_l_bfgs_b_train, pll_l_bfgs_b_test, ll_l_bfgs_b_train, ll_l_bfgs_b_test, reg_weights, pred_weights], f_save)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
